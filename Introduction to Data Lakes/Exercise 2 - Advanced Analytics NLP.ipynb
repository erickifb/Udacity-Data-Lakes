{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Advanced Analytics NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:12.472305Z",
     "start_time": "2018-12-04T16:27:10.886061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spark-nlp==1.7.3 in /opt/conda/lib/python3.6/site-packages (1.7.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-nlp==1.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sparknlp\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/07/45486033981458596a8273782c3230bf6279d1266c96de6b654fe40e765b/sparknlp-1.0.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from sparknlp) (1.12.1)\n",
      "Requirement already satisfied: spark-nlp in /opt/conda/lib/python3.6/site-packages (from sparknlp) (1.8.2)\n",
      "Installing collected packages: sparknlp\n",
      "Successfully installed sparknlp-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install spark-nlp==1.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:14.748410Z",
     "start_time": "2018-12-04T16:28:14.342555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a spark context that includes a 3rd party jar for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:35.841869Z",
     "start_time": "2018-12-04T16:28:31.934985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://2126b9b15a2e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3a421715c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#jarPath = \"spark-nlp-assembly-1.7.3.jar\"\n",
    "\n",
    "\n",
    "# Todo\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .config(\"spark.jars.packages\", 'com.johnsnowlabs.nlp:spark-nlp_2.11:1.8.2')\\\n",
    "        .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read multiple files in a dir as one Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:40.343540Z",
     "start_time": "2018-12-04T16:28:35.844308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "root\n",
      " |-- data: struct (nullable = true)\n",
      " |    |-- approved_at_utc: string (nullable = true)\n",
      " |    |-- approved_by: string (nullable = true)\n",
      " |    |-- archived: boolean (nullable = true)\n",
      " |    |-- author: string (nullable = true)\n",
      " |    |-- author_flair_background_color: string (nullable = true)\n",
      " |    |-- author_flair_css_class: string (nullable = true)\n",
      " |    |-- author_flair_richtext: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- author_flair_template_id: string (nullable = true)\n",
      " |    |-- author_flair_text: string (nullable = true)\n",
      " |    |-- author_flair_text_color: string (nullable = true)\n",
      " |    |-- author_flair_type: string (nullable = true)\n",
      " |    |-- author_fullname: string (nullable = true)\n",
      " |    |-- author_patreon_flair: boolean (nullable = true)\n",
      " |    |-- banned_at_utc: string (nullable = true)\n",
      " |    |-- banned_by: string (nullable = true)\n",
      " |    |-- can_gild: boolean (nullable = true)\n",
      " |    |-- can_mod_post: boolean (nullable = true)\n",
      " |    |-- category: string (nullable = true)\n",
      " |    |-- clicked: boolean (nullable = true)\n",
      " |    |-- content_categories: string (nullable = true)\n",
      " |    |-- contest_mode: boolean (nullable = true)\n",
      " |    |-- created: double (nullable = true)\n",
      " |    |-- created_utc: double (nullable = true)\n",
      " |    |-- crosspost_parent: string (nullable = true)\n",
      " |    |-- crosspost_parent_list: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- approved_at_utc: string (nullable = true)\n",
      " |    |    |    |-- approved_by: string (nullable = true)\n",
      " |    |    |    |-- archived: boolean (nullable = true)\n",
      " |    |    |    |-- author: string (nullable = true)\n",
      " |    |    |    |-- author_flair_background_color: string (nullable = true)\n",
      " |    |    |    |-- author_flair_css_class: string (nullable = true)\n",
      " |    |    |    |-- author_flair_richtext: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- author_flair_template_id: string (nullable = true)\n",
      " |    |    |    |-- author_flair_text: string (nullable = true)\n",
      " |    |    |    |-- author_flair_text_color: string (nullable = true)\n",
      " |    |    |    |-- author_flair_type: string (nullable = true)\n",
      " |    |    |    |-- author_fullname: string (nullable = true)\n",
      " |    |    |    |-- author_patreon_flair: boolean (nullable = true)\n",
      " |    |    |    |-- banned_at_utc: string (nullable = true)\n",
      " |    |    |    |-- banned_by: string (nullable = true)\n",
      " |    |    |    |-- can_gild: boolean (nullable = true)\n",
      " |    |    |    |-- can_mod_post: boolean (nullable = true)\n",
      " |    |    |    |-- category: string (nullable = true)\n",
      " |    |    |    |-- clicked: boolean (nullable = true)\n",
      " |    |    |    |-- content_categories: string (nullable = true)\n",
      " |    |    |    |-- contest_mode: boolean (nullable = true)\n",
      " |    |    |    |-- created: double (nullable = true)\n",
      " |    |    |    |-- created_utc: double (nullable = true)\n",
      " |    |    |    |-- distinguished: string (nullable = true)\n",
      " |    |    |    |-- domain: string (nullable = true)\n",
      " |    |    |    |-- downs: long (nullable = true)\n",
      " |    |    |    |-- edited: boolean (nullable = true)\n",
      " |    |    |    |-- gilded: long (nullable = true)\n",
      " |    |    |    |-- gildings: struct (nullable = true)\n",
      " |    |    |    |    |-- gid_1: long (nullable = true)\n",
      " |    |    |    |    |-- gid_2: long (nullable = true)\n",
      " |    |    |    |    |-- gid_3: long (nullable = true)\n",
      " |    |    |    |-- hidden: boolean (nullable = true)\n",
      " |    |    |    |-- hide_score: boolean (nullable = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- is_crosspostable: boolean (nullable = true)\n",
      " |    |    |    |-- is_meta: boolean (nullable = true)\n",
      " |    |    |    |-- is_original_content: boolean (nullable = true)\n",
      " |    |    |    |-- is_reddit_media_domain: boolean (nullable = true)\n",
      " |    |    |    |-- is_robot_indexable: boolean (nullable = true)\n",
      " |    |    |    |-- is_self: boolean (nullable = true)\n",
      " |    |    |    |-- is_video: boolean (nullable = true)\n",
      " |    |    |    |-- likes: string (nullable = true)\n",
      " |    |    |    |-- link_flair_background_color: string (nullable = true)\n",
      " |    |    |    |-- link_flair_css_class: string (nullable = true)\n",
      " |    |    |    |-- link_flair_richtext: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- link_flair_template_id: string (nullable = true)\n",
      " |    |    |    |-- link_flair_text: string (nullable = true)\n",
      " |    |    |    |-- link_flair_text_color: string (nullable = true)\n",
      " |    |    |    |-- link_flair_type: string (nullable = true)\n",
      " |    |    |    |-- locked: boolean (nullable = true)\n",
      " |    |    |    |-- media: string (nullable = true)\n",
      " |    |    |    |-- media_only: boolean (nullable = true)\n",
      " |    |    |    |-- mod_note: string (nullable = true)\n",
      " |    |    |    |-- mod_reason_by: string (nullable = true)\n",
      " |    |    |    |-- mod_reason_title: string (nullable = true)\n",
      " |    |    |    |-- mod_reports: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- no_follow: boolean (nullable = true)\n",
      " |    |    |    |-- num_comments: long (nullable = true)\n",
      " |    |    |    |-- num_crossposts: long (nullable = true)\n",
      " |    |    |    |-- num_reports: string (nullable = true)\n",
      " |    |    |    |-- over_18: boolean (nullable = true)\n",
      " |    |    |    |-- parent_whitelist_status: string (nullable = true)\n",
      " |    |    |    |-- permalink: string (nullable = true)\n",
      " |    |    |    |-- pinned: boolean (nullable = true)\n",
      " |    |    |    |-- pwls: long (nullable = true)\n",
      " |    |    |    |-- quarantine: boolean (nullable = true)\n",
      " |    |    |    |-- removal_reason: string (nullable = true)\n",
      " |    |    |    |-- report_reasons: string (nullable = true)\n",
      " |    |    |    |-- saved: boolean (nullable = true)\n",
      " |    |    |    |-- score: long (nullable = true)\n",
      " |    |    |    |-- secure_media: string (nullable = true)\n",
      " |    |    |    |-- selftext: string (nullable = true)\n",
      " |    |    |    |-- selftext_html: string (nullable = true)\n",
      " |    |    |    |-- send_replies: boolean (nullable = true)\n",
      " |    |    |    |-- spoiler: boolean (nullable = true)\n",
      " |    |    |    |-- stickied: boolean (nullable = true)\n",
      " |    |    |    |-- subreddit: string (nullable = true)\n",
      " |    |    |    |-- subreddit_id: string (nullable = true)\n",
      " |    |    |    |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |    |    |    |-- subreddit_subscribers: long (nullable = true)\n",
      " |    |    |    |-- subreddit_type: string (nullable = true)\n",
      " |    |    |    |-- suggested_sort: string (nullable = true)\n",
      " |    |    |    |-- thumbnail: string (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- ups: long (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |    |-- user_reports: array (nullable = true)\n",
      " |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- view_count: string (nullable = true)\n",
      " |    |    |    |-- visited: boolean (nullable = true)\n",
      " |    |    |    |-- whitelist_status: string (nullable = true)\n",
      " |    |    |    |-- wls: long (nullable = true)\n",
      " |    |-- distinguished: string (nullable = true)\n",
      " |    |-- domain: string (nullable = true)\n",
      " |    |-- downs: long (nullable = true)\n",
      " |    |-- edited: boolean (nullable = true)\n",
      " |    |-- gilded: long (nullable = true)\n",
      " |    |-- gildings: struct (nullable = true)\n",
      " |    |    |-- gid_1: long (nullable = true)\n",
      " |    |    |-- gid_2: long (nullable = true)\n",
      " |    |    |-- gid_3: long (nullable = true)\n",
      " |    |-- hidden: boolean (nullable = true)\n",
      " |    |-- hide_score: boolean (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- is_crosspostable: boolean (nullable = true)\n",
      " |    |-- is_meta: boolean (nullable = true)\n",
      " |    |-- is_original_content: boolean (nullable = true)\n",
      " |    |-- is_reddit_media_domain: boolean (nullable = true)\n",
      " |    |-- is_robot_indexable: boolean (nullable = true)\n",
      " |    |-- is_self: boolean (nullable = true)\n",
      " |    |-- is_video: boolean (nullable = true)\n",
      " |    |-- likes: string (nullable = true)\n",
      " |    |-- link_flair_background_color: string (nullable = true)\n",
      " |    |-- link_flair_css_class: string (nullable = true)\n",
      " |    |-- link_flair_richtext: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- link_flair_template_id: string (nullable = true)\n",
      " |    |-- link_flair_text: string (nullable = true)\n",
      " |    |-- link_flair_text_color: string (nullable = true)\n",
      " |    |-- link_flair_type: string (nullable = true)\n",
      " |    |-- locked: boolean (nullable = true)\n",
      " |    |-- media: string (nullable = true)\n",
      " |    |-- media_only: boolean (nullable = true)\n",
      " |    |-- mod_note: string (nullable = true)\n",
      " |    |-- mod_reason_by: string (nullable = true)\n",
      " |    |-- mod_reason_title: string (nullable = true)\n",
      " |    |-- mod_reports: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- no_follow: boolean (nullable = true)\n",
      " |    |-- num_comments: long (nullable = true)\n",
      " |    |-- num_crossposts: long (nullable = true)\n",
      " |    |-- num_reports: string (nullable = true)\n",
      " |    |-- over_18: boolean (nullable = true)\n",
      " |    |-- parent_whitelist_status: string (nullable = true)\n",
      " |    |-- permalink: string (nullable = true)\n",
      " |    |-- pinned: boolean (nullable = true)\n",
      " |    |-- pwls: long (nullable = true)\n",
      " |    |-- quarantine: boolean (nullable = true)\n",
      " |    |-- removal_reason: string (nullable = true)\n",
      " |    |-- report_reasons: string (nullable = true)\n",
      " |    |-- saved: boolean (nullable = true)\n",
      " |    |-- score: long (nullable = true)\n",
      " |    |-- secure_media: string (nullable = true)\n",
      " |    |-- selftext: string (nullable = true)\n",
      " |    |-- selftext_html: string (nullable = true)\n",
      " |    |-- send_replies: boolean (nullable = true)\n",
      " |    |-- spoiler: boolean (nullable = true)\n",
      " |    |-- stickied: boolean (nullable = true)\n",
      " |    |-- subreddit: string (nullable = true)\n",
      " |    |-- subreddit_id: string (nullable = true)\n",
      " |    |-- subreddit_name_prefixed: string (nullable = true)\n",
      " |    |-- subreddit_subscribers: long (nullable = true)\n",
      " |    |-- subreddit_type: string (nullable = true)\n",
      " |    |-- suggested_sort: string (nullable = true)\n",
      " |    |-- thumbnail: string (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- ups: long (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- user_reports: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- view_count: string (nullable = true)\n",
      " |    |-- visited: boolean (nullable = true)\n",
      " |    |-- whitelist_status: string (nullable = true)\n",
      " |    |-- wls: long (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataPath = \"./data/reddit/*.json\"\n",
    "df = spark.read.json(dataPath)\n",
    "print(df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deal with Struct type to query subfields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:40.819564Z",
     "start_time": "2018-12-04T16:28:40.345335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corp said it has discovered hacking targeting democratic institutions, think tanks, and non-profit organizations in Europe.</td>\n",
       "      <td>jaykirsch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deutsche Bank reportedly planned to extend the dates of $340 million in loans to Trump Organization to avoid a potential nightmare of chasing a sitting president for cash</td>\n",
       "      <td>canuck_burger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iranian \"morality police\" were forced to fire warning shots when a crowd intervened to prevent them from arresting two women for not wearing a hijab. The incident occurred in Tehran's northeastern Narmak neighbourhood on Friday night, and ended with a mob tearing the door off a police vehicle.</td>\n",
       "      <td>honolulu_oahu_mod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump administration 'pushing Saudi nuclear deal' which could benefit company linked to Jared Kushner - Senior Trump administration officials pushed a project to share nuclear power technology with Saudi Arabia over the objections of ethics officials, according to a congressional report</td>\n",
       "      <td>madam1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASA Happily Reports the Earth is Greener, With More Trees Than 20 Years Ago–and It's Thanks to China, India</td>\n",
       "      <td>purplexxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                    title  \\\n",
       "0                                                                                                                                                                   Microsoft Corp said it has discovered hacking targeting democratic institutions, think tanks, and non-profit organizations in Europe.   \n",
       "1                                                                                                                              Deutsche Bank reportedly planned to extend the dates of $340 million in loans to Trump Organization to avoid a potential nightmare of chasing a sitting president for cash   \n",
       "2  Iranian \"morality police\" were forced to fire warning shots when a crowd intervened to prevent them from arresting two women for not wearing a hijab. The incident occurred in Tehran's northeastern Narmak neighbourhood on Friday night, and ended with a mob tearing the door off a police vehicle.   \n",
       "3         Trump administration 'pushing Saudi nuclear deal' which could benefit company linked to Jared Kushner - Senior Trump administration officials pushed a project to share nuclear power technology with Saudi Arabia over the objections of ethics officials, according to a congressional report   \n",
       "4                                                                                                                                                                                            NASA Happily Reports the Earth is Greener, With More Trees Than 20 Years Ago–and It's Thanks to China, India   \n",
       "\n",
       "              author  \n",
       "0          jaykirsch  \n",
       "1      canuck_burger  \n",
       "2  honolulu_oahu_mod  \n",
       "3             madam1  \n",
       "4          purplexxx  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = \"data.title\"\n",
    "author = \"data.author\"\n",
    "dfAuthorTilte = df.select(title, author)\n",
    "dfAuthorTilte.limit(5).toPandas()\n",
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to implement the equivalent of flatMap in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:28:43.068755Z",
     "start_time": "2018-12-04T16:28:40.826537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>to</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>for</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>and</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>on</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>over</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word  count\n",
       "0    to     58\n",
       "1   the     46\n",
       "2    of     42\n",
       "3    in     41\n",
       "4     a     25\n",
       "5   for     20\n",
       "6   and     19\n",
       "7  from     12\n",
       "8    on     11\n",
       "9  over     10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "dfWordCount = df.select(F.explode(F.split(title,\"\\\\s+\")).alias(\"word\")).groupBy(\"word\").count().orderBy(F.desc(\"count\"))\n",
    "dfWordCount.limit(10).toPandas()\n",
    "\n",
    "#dfWordCount = # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use an NLP libary to do Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:10.967990Z",
     "start_time": "2018-12-04T16:28:43.072151Z"
    }
   },
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'requirement failed: Was not found appropriate resource to download for request: ResourceRequest(pos_anc,Some(en),public/models,1.8.2,2.4.3) with downloader: com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader@fead1e9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel.\n: java.lang.IllegalArgumentException: requirement failed: Was not found appropriate resource to download for request: ResourceRequest(pos_anc,Some(en),public/models,1.8.2,2.4.3) with downloader: com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader@fead1e9\n\tat scala.Predef$.require(Predef.scala:224)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadResource(ResourceDownloader.scala:99)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:114)\n\tat com.johnsnowlabs.nlp.pretrained.ResourceDownloader$.downloadModel(ResourceDownloader.scala:109)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader$.downloadModel(ResourceDownloader.scala:185)\n\tat com.johnsnowlabs.nlp.pretrained.PythonResourceDownloader.downloadModel(ResourceDownloader.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3e3c39733fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pos_anc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token\"\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdep_parser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDependencyParserModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dependency_conllu'\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0msetInputCols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"document\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m.\u001b[0m\u001b[0msetOutputCol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dependency\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sparknlp/annotator.py\u001b[0m in \u001b[0;36mpretrained\u001b[0;34m(name, language, remote_loc)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0minfix_patterns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfixPatterns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfix_patterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetExceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"Sets words that won't be affected by tokenization rules.\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sparknlp/pretrained/__init__.py\u001b[0m in \u001b[0;36mdownloadModel\u001b[0;34m(reader, name, language, remote_loc)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sparknlp/internal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, reader, name, language, remote_loc)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_new_java_obj\u001b[0;34m(java_class, *args)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mjava_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mjava_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjava_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mjava_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.3-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'requirement failed: Was not found appropriate resource to download for request: ResourceRequest(pos_anc,Some(en),public/models,1.8.2,2.4.3) with downloader: com.johnsnowlabs.nlp.pretrained.S3ResourceDownloader@fead1e9'"
     ]
    }
   ],
   "source": [
    "#from com.johnsnowlabs.nlp.pretrained.pipeline.en import BasicPipeline as bp\n",
    "#dfAnnotated = # Todo\n",
    "#!pip install spark-nlp==3.4.2 pyspark==3.1.2\n",
    "\n",
    "!pip install -q pyspark==3.1.2 spark-nlp\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "pos = PerceptronModel.pretrained(\"pos_anc\", 'en')\\\n",
    "        .setInputCols(\"document\", \"token\")\\\n",
    "        .setOutputCol(\"pos\")\n",
    "\n",
    "dep_parser = DependencyParserModel.pretrained('dependency_conllu')\\\n",
    "        .setInputCols([\"document\", \"pos\", \"token\"])\\\n",
    "        .setOutputCol(\"dependency\")\n",
    "\n",
    "\n",
    "typed_dep_parser = TypedDependencyParserModel.pretrained('dependency_typed_conllu')\\\n",
    "        .setInputCols([\"token\", \"pos\", \"dependency\"])\\\n",
    "        .setOutputCol(\"dependency_type\")\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(\n",
    "      stages = [\n",
    "          documentAssembler,\n",
    "          tokenizer,\n",
    "          pos,\n",
    "          dep_parser,\n",
    "          typed_dep_parser\n",
    "      ])\n",
    "\n",
    "#dfAnnotated = PretrainedPipeline(dfAuthorTilte, \"title\")\n",
    "dfAnnotated.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with Map type to query subfields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:11.430140Z",
     "start_time": "2018-12-04T16:29:10.973865Z"
    }
   },
   "outputs": [],
   "source": [
    "dfPos = # Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:12.012202Z",
     "start_time": "2018-12-04T16:29:11.432322Z"
    }
   },
   "outputs": [],
   "source": [
    "dfPos= # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep only proper nouns NNP or NNPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:12.551881Z",
     "start_time": "2018-12-04T16:29:12.014196Z"
    }
   },
   "outputs": [],
   "source": [
    "nnpFilter = \"pos.result = 'NNP' or pos.result = 'NNPS' \"\n",
    "dfNNP = # Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract columns form a map in a col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T16:29:12.811100Z",
     "start_time": "2018-12-04T16:29:12.556429Z"
    }
   },
   "outputs": [],
   "source": [
    "dfWordTag = # Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "# Todo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "84px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
